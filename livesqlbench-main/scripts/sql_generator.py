#!/usr/bin/env python3
"""
SQLç”Ÿæˆå™¨æ¨¡å— - è´Ÿè´£åŒæ¨¡å‹SQLç”Ÿæˆå’Œæ™ºèƒ½é€‰æ‹©
"""

from typing import Dict, Any
from models import TableSelection, ExampleSelectionResult
from nl2sql_utils import get_selected_mschema


class SQLGenerator:
    """SQLç”Ÿæˆå™¨ç±» - è´Ÿè´£åŒæ¨¡å‹ååŒç”ŸæˆSQL"""
    
    def __init__(self, llm_openai, llm_anthropic, db_id: str, db):
        """
        åˆå§‹åŒ–SQLç”Ÿæˆå™¨
        
        Args:
            llm_openai: OpenAIæ¨¡å‹å®ä¾‹
            llm_anthropic: Anthropicæ¨¡å‹å®ä¾‹
            db_id: æ•°æ®åº“ID
            db: æ•°æ®åº“è¿æ¥å®ä¾‹
        """
        self.llm_openai = llm_openai
        self.llm_anthropic = llm_anthropic
        self.db_id = db_id
        self.db = db
    
    def generate_sql_dual_model(self, question: str, table_selection: TableSelection, 
                               example_selection: ExampleSelectionResult = None) -> Dict[str, Any]:
        """
        åŒæ¨¡å‹ç”ŸæˆSQLæŸ¥è¯¢ï¼šAnthropic + OpenAI ååŒç”Ÿæˆï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜SQL
        
        Args:
            question: è‡ªç„¶è¯­è¨€é—®é¢˜
            table_selection: è¡¨é€‰æ‹©ç»“æœ
            example_selection: ç¤ºä¾‹é€‰æ‹©ç»“æœ
            
        Returns:
            åŒ…å«SQLå’Œæ¨ç†è¿‡ç¨‹çš„å­—å…¸
        """
        from prompt_builder import PromptBuilder
        from sql_executor import SQLExecutor
        
        # æ„å»ºæç¤ºè¯
        prompt_builder = PromptBuilder(self.db_id)
        prompt = prompt_builder.build_sql_generation_prompt(
            question, table_selection, example_selection
        )
        
        try:
            print("ğŸ¤– å¯åŠ¨åŒæ¨¡å‹SQLç”Ÿæˆ...")
            
            # æ‰“å°å®Œæ•´çš„SQLç”Ÿæˆprompt
            self._print_sql_generation_prompt(prompt, question, table_selection, example_selection)
            
            # 1. Anthropic ç”Ÿæˆ SQL
            print("ğŸ§  Anthropic ç”ŸæˆSQLä¸­...")
            response_anthropic = self.llm_anthropic.invoke(prompt)
            sql_anthropic = self._extract_sql_from_anthropic_response(response_anthropic)
            print(f"âœ… Anthropic æå–çš„SQL: {sql_anthropic}")
            
            # 2. OpenAI ç”Ÿæˆ SQL
            print("ğŸ§  OpenAI ç”ŸæˆSQLä¸­...")
            response_openai = self.llm_openai.invoke(prompt)
            sql_openai = self._extract_sql_from_response(response_openai.content.strip())
            print(f"âœ… OpenAI æå–çš„SQL: {sql_openai}")
            
            # 3. ä½¿ç”¨æ‰§è¡Œç»“æœæ¯”è¾ƒæ–¹æ³•é€‰æ‹©æœ€ä¼˜SQL
            print("ğŸ” é€šè¿‡æ‰§è¡Œç»“æœé€‰æ‹©æœ€ä¼˜SQLä¸­...")
            executor = SQLExecutor(self.db)
            selected_sql = self._select_best_sql_with_execution(
                question, sql_anthropic, sql_openai, table_selection, 
                example_selection, executor
            )
            
            return {
                'sql': selected_sql,
                'reasoning': f'åŒæ¨¡å‹ååŒç”Ÿæˆï¼šAnthropicå’ŒOpenAIåˆ†åˆ«ç”ŸæˆSQLï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç»“æœ',
                'confidence': 0.9,
                'anthropic_sql': sql_anthropic,
                'openai_sql': sql_openai,
                'selected_model': 'dual_model_selection'
            }
            
        except Exception as e:
            print(f"âŒ åŒæ¨¡å‹SQLç”Ÿæˆå¤±è´¥: {str(e)}")
            # å›é€€åˆ°å•æ¨¡å‹
            return self._fallback_single_model(prompt, str(e))
    
    def _extract_sql_from_anthropic_response(self, response_anthropic) -> str:
        """ä»Anthropicå“åº”ä¸­æå–SQL"""
        raw_anthropic = ""
        if isinstance(response_anthropic.content, list) and len(response_anthropic.content) > 0:
            # æŸ¥æ‰¾ type='text' çš„å­—å…¸ï¼Œæå– text å­—æ®µ
            for item in response_anthropic.content:
                if isinstance(item, dict) and item.get('type') == 'text':
                    raw_anthropic = item.get('text', '')
                    break
            if not raw_anthropic:
                raw_anthropic = str(response_anthropic.content)
        else:
            raw_anthropic = response_anthropic.content
        
        return self._extract_sql_from_response(raw_anthropic)
    
    def _extract_sql_from_response(self, response_text: str) -> str:
        """
        ä»æ¨¡å‹å“åº”ä¸­æå–SQLè¯­å¥
        
        Args:
            response_text: æ¨¡å‹çš„åŸå§‹å“åº”æ–‡æœ¬
            
        Returns:
            æå–çš„SQLè¯­å¥
        """
        # åŸºæœ¬æ¸…ç†
        text = response_text.strip().replace(""", "'").replace(""", "'").replace("\\", "")
        
        # å¦‚æœæ˜¯ ```sql ä»£ç å—æ ¼å¼ï¼Œæå–SQL
        if "```sql" in text:
            lines = text.strip().splitlines()
            sql_lines = []
            in_sql_block = False
            for line in lines:
                if line.strip().startswith("```sql"):
                    in_sql_block = True
                    continue
                elif line.strip().startswith("```") and in_sql_block:
                    break
                elif in_sql_block:
                    sql_lines.append(line)
            if sql_lines:
                return "\n".join(sql_lines).strip().rstrip(";")
        
        # å¦‚æœåŒ…å«SELECTå…³é”®å­—ï¼Œå°è¯•æå–SQLéƒ¨åˆ†
        if "SELECT" in text.upper():
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªSELECTçš„ä½ç½®
            select_pos = text.upper().find("SELECT")
            sql_part = text[select_pos:].strip()
            # ç§»é™¤å¯èƒ½çš„ç»“å°¾åˆ†å·
            return sql_part.rstrip(";")
        
        # ç›´æ¥è¿”å›æ¸…ç†åçš„æ–‡æœ¬
        return text.strip().rstrip(";")
    
    def _select_best_sql_with_execution(self, question: str, sql_anthropic: str, sql_openai: str, 
                                       table_selection: TableSelection, 
                                       example_selection: ExampleSelectionResult,
                                       executor) -> str:
        """
        é€šè¿‡æ‰§è¡ŒSQLå¹¶æ¯”è¾ƒç»“æœæ¥é€‰æ‹©æœ€ä¼˜SQLï¼Œæˆ–ç”Ÿæˆæ–°çš„æ­£ç¡®SQL
        """
        # ç¡®ä¿tablesæ˜¯åˆ—è¡¨
        if isinstance(table_selection.tables, str):
            if table_selection.tables.startswith('[') and table_selection.tables.endswith(']'):
                import ast
                try:
                    tables_list = ast.literal_eval(table_selection.tables)
                except:
                    tables_list = [table_selection.tables]
            else:
                tables_list = [table_selection.tables]
        else:
            tables_list = table_selection.tables
            
        selected_table_infos = get_selected_mschema(self.db_id, tables_list)
        
        # æ‰§è¡Œä¸¤æ¡SQL
        print("ğŸ” æ‰§è¡ŒAnthropic SQL...")
        result_anthropic = executor.execute_sql_safely(sql_anthropic)
        print(f"âœ… Anthropicæ‰§è¡Œç»“æœ: {result_anthropic['success']}, è¡Œæ•°: {result_anthropic.get('row_count', 0)}")
        
        print("ğŸ” æ‰§è¡ŒOpenAI SQL...")
        result_openai = executor.execute_sql_safely(sql_openai)
        print(f"âœ… OpenAIæ‰§è¡Œç»“æœ: {result_openai['success']}, è¡Œæ•°: {result_openai.get('row_count', 0)}")
        
        # æ„å»ºfew-shotæ–‡æœ¬
        few_shot_text = example_selection.few_shot_text if example_selection else ""
        
        # ç»Ÿä¸€çš„SQLé€‰æ‹©/ç”Ÿæˆprompt
        unified_prompt = f"""ä½ æ˜¯ä¸€ä½SQLiteæ•°æ®åº“ä¸“å®¶ã€‚è¯·åˆ†æä¸¤æ¡SQLçš„æ‰§è¡Œç»“æœï¼Œç„¶åæŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

1. é¦–å…ˆåˆ¤æ–­ä¸¤æ¡SQLçš„æ‰§è¡Œç»“æœæ˜¯å¦ç›¸åŒï¼ˆå¿½ç•¥é¡ºåºã€æ ¼å¼ã€åˆ—å±æ€§åç­‰æ— å…³ç»“æœæ­£ç¡®æ€§çš„å·®å¼‚ï¼‰
2. å¦‚æœç»“æœç›¸åŒä¸”éƒ½æ­£ç¡®å›ç­”äº†ç”¨æˆ·é—®é¢˜ï¼Œè¯·ä»ä¸­é€‰æ‹©æ›´ä¼˜çš„ä¸€æ¡ï¼ˆè€ƒè™‘ç®€æ´æ€§ã€æ•ˆç‡ã€å¯è¯»æ€§ï¼‰
3. å¦‚æœç»“æœä¸åŒæˆ–æœ‰æ‰§è¡Œå¤±è´¥ï¼Œè¯·ç”Ÿæˆä¸€æ¡æ–°çš„æ­£ç¡®SQL

ç”¨æˆ·é—®é¢˜: {question}

è¡¨ç»“æ„ä¿¡æ¯ï¼ˆM-Schemaï¼‰:
{selected_table_infos}

å‚è€ƒç¤ºä¾‹:
{few_shot_text}

SQL 1 (Anthropic): {sql_anthropic}
æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if result_anthropic['success'] else 'å¤±è´¥'}
æ‰§è¡Œç»“æœ: {result_anthropic['result'] if result_anthropic['success'] else result_anthropic['error']}

SQL 2 (OpenAI): {sql_openai}
æ‰§è¡ŒçŠ¶æ€: {'æˆåŠŸ' if result_openai['success'] else 'å¤±è´¥'}
æ‰§è¡Œç»“æœ: {result_openai['result'] if result_openai['success'] else result_openai['error']}

è¦æ±‚ï¼š
- å¦‚æœé€‰æ‹©ç°æœ‰SQLï¼Œå¿…é¡»å®Œæ•´è¿”å›é€‰ä¸­çš„SQL
- å¦‚æœç”Ÿæˆæ–°SQLï¼Œä¸¥æ ¼ä½¿ç”¨æä¾›çš„è¡¨ç»“æ„ä¸­çš„è¡¨åå’Œå­—æ®µå
- ç¡®ä¿SQLè¯­æ³•æ­£ç¡®ï¼Œç¬¦åˆSQLiteæ ‡å‡†
- é€»è¾‘æ­£ç¡®ï¼Œèƒ½å¤Ÿå‡†ç¡®å›ç­”ç”¨æˆ·é—®é¢˜

ä»…è¿”å›æœ€ç»ˆçš„SQLè¯­å¥ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–ä»£ç å—æ ‡è®°ã€‚
"""
        
        try:
            print("ğŸ” SQLé€‰æ‹©/ç”Ÿæˆæ¨¡å‹çš„è¾“å…¥prompt:")
            print("=" * 80)
            print(unified_prompt)
            print("=" * 80)
            
            response = self.llm_openai.invoke(unified_prompt)
            selected_sql = response.content.strip()
            
            # æ¸…ç†SQL
            if selected_sql.startswith("```sql"):
                lines = selected_sql.strip().splitlines()
                selected_sql = "\n".join(line for line in lines if not line.strip().startswith("```")).strip(";")
            
            print(f"ğŸ¯ é€‰æ‹©/ç”Ÿæˆçš„SQL: {selected_sql}")
            return selected_sql
            
        except Exception as e:
            print(f"âš ï¸ SQLé€‰æ‹©/ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨fallbackç­–ç•¥: {str(e)}")
            # ä¼˜å…ˆè¿”å›æ‰§è¡ŒæˆåŠŸçš„SQL
            if result_anthropic['success'] and not result_openai['success']:
                return sql_anthropic
            elif result_openai['success'] and not result_anthropic['success']:
                return sql_openai
            else:
                return sql_anthropic  # é»˜è®¤è¿”å›Anthropicç»“æœ
    
    def _fallback_single_model(self, prompt: str, error: str) -> Dict[str, Any]:
        """å•æ¨¡å‹å›é€€ç­–ç•¥"""
        try:
            print("ğŸ”„ å›é€€åˆ°å•æ¨¡å‹ç”Ÿæˆ...")
            response = self.llm_openai.invoke(prompt)
            return {
                'sql': response.content.strip(),
                'reasoning': f'åŒæ¨¡å‹å¤±è´¥ï¼Œå›é€€åˆ°OpenAIå•æ¨¡å‹ç”Ÿæˆã€‚é”™è¯¯: {error}',
                'confidence': 0.7
            }
        except Exception as e2:
            return {
                'sql': '',
                'reasoning': f'SQLç”Ÿæˆå®Œå…¨å¤±è´¥: {str(e2)}',
                'confidence': 0.0
            }
    
    def _print_sql_generation_prompt(self, prompt: str, question: str, 
                                   table_selection: TableSelection, 
                                   example_selection: ExampleSelectionResult = None):
        """æ‰“å°SQLç”Ÿæˆçš„å®Œæ•´promptä¿¡æ¯"""
        print("\n" + "="*100)
        print("ğŸ“‹ SQLç”ŸæˆPromptè¯¦æƒ…")
        print("="*100)
        
        print(f"ğŸ¯ ç”¨æˆ·é—®é¢˜: {question}")
        print(f"ğŸ—ƒï¸ æ•°æ®åº“ID: {self.db_id}")
        print(f"ğŸ“Š é€‰ä¸­çš„è¡¨: {', '.join(table_selection.tables)}")
        print(f"ğŸ¯ è¡¨é€‰æ‹©ç½®ä¿¡åº¦: {table_selection.confidence_score:.2f}")
        
        # æ‰“å°few-shotç¤ºä¾‹ä¿¡æ¯
        if example_selection and example_selection.few_shot_text:
            print(f"ğŸ“š Few-shotæ–¹æ³•: {example_selection.selection_method}")
            print(f"ğŸ“Š å¯ç”¨ç¤ºä¾‹æ€»æ•°: {example_selection.total_examples}")
            print(f"âœ… é€‰ä¸­ç¤ºä¾‹æ•°é‡: {len(example_selection.selected_examples)}")
        else:
            print("âš ï¸ æœªä½¿ç”¨Few-shotç¤ºä¾‹")
        
        print(f"\nğŸ§¾ å®Œæ•´Promptå†…å®¹:")
        print("-" * 100)
        print(prompt)
        print("-" * 100)
        print(f"ğŸ“ Promptæ€»é•¿åº¦: {len(prompt)} å­—ç¬¦")
        print("="*100 + "\n")